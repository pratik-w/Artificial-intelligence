{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Pratik Warade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Solution to the Towers of Hanoi Puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview :\n",
    "In this assignment, I have implemented the reinforcement learning to solve Tower of Hanoi Puzzle with 3 pegs and for 4 Pegs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background :\n",
    "\n",
    "\n",
    "The Tower of Hanoi game consists of three pegs and a number of disks of different sizes which can slide onto the pegs. The puzzle starts with all disks stacked on the first peg in ascending order, with the largest at the bottom and the smallest on top. The objective of the game is to move all the disks to the third peg. The only legal moves are those which take the top-most disk from one peg to another, with the restriction that a disk may never be placed upon a smaller disk. Figure 1 shows the optimal solution for 4 disks.\n",
    "<img src= \"http://www.cs.colostate.edu/~pswarade/pratik_imp/Tower_of_Hanoi.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is RL (Reinforcement Learning)? \n",
    "In simple words,Reinforcement Learning is all about how we can make good decision through trial and error.  It is the interaction between the \"agent\" and the \"environment\".  \n",
    "Repeat the following steps until reaching a termination condition :  \n",
    "  1) The agent observe the environment having state s  \n",
    "  2) Out of all possible actions, the agent need to decide which action to take.  (this is called \"policy\", which is a function that output an action given the current state)  \n",
    "  3) Agent take the action, and the environment receive that action  \n",
    "  4) Through a transition matrix model, environment determine what is the next state and proceed to that state  \n",
    "  5) Through a reward distribution model, the environment determines the reward to the agent given he take action a at state s\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "<img src= \"http://www.cs.colostate.edu/~pswarade/pratik_imp/reinforcement.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "First, how should we represent the state of this puzzle?  We need to keep track of which disks are on which pegs. I Named the disks 1, 2, and 3, with 1 being the smallest disk and 3 being the largest. The set of disks on a peg can be represented as a list of integers.  Then the state can be a list of three lists.\n",
    "\n",
    "For example, the starting state with all disks being on the left peg would be `[[1, 2, 3], [], []]`.  After moving disk 1 to peg 2, we have `[[2, 3], [1], []]`.\n",
    "\n",
    "To represent that move I just made, I can use a list of two peg numbers, like `[1, 2]`, representing a move of the top disk on peg 1 to peg 2.\n",
    "\n",
    "\n",
    "\n",
    "Now on to some functions. Define at least the following functions. Examples showing required output appear below.\n",
    "\n",
    "   - `printState(state)`: prints the state in the form shown below\n",
    "   - `validMoves(state)`: returns list of moves that are valid from `state`\n",
    "   - `makeMove(state, move)`: returns new (copy of) state after move has been applied.\n",
    "   - `trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF)`: train the Q function for number of repetitions, decaying epsilon at start of each repetition. Returns Q and list or array of number of steps to reach goal for each repetition.\n",
    "   - `testQ(Q, maxSteps, validMovesF, makeMoveF)`: without updating Q, use Q to find greedy action each step until goal is found. Return path of states.\n",
    "\n",
    "A function that you might choose to implement is\n",
    "\n",
    "   - `stateMoveTuple(state, move)`: returns tuple of state and move.  \n",
    "    \n",
    "This is useful for converting state and move to a key to be used for the Q dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required Imports \n",
    "import numpy as np\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "from copy import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets start by simply printing towe of Hanoi states. Following code call getStates method that will return p,q,r states from input board.\n",
    "# Once We get p,q,r list. I then, check for size and based  on that, I update states with blanks or values and print using .format.\n",
    "\n",
    "def getState(state):\n",
    "    i=0\n",
    "    states=deepcopy(state)\n",
    "    #looping through all states and assigning them to p,q,r state\n",
    "    for s in states :\n",
    "        if(i==0):\n",
    "            p=s            \n",
    "          #  print (\"P= \",p)\n",
    "        if(i==1):\n",
    "            q=s\n",
    "           # print (\"q= \",q)\n",
    "        if(i==2):\n",
    "            r=s\n",
    "            #print (\"r= \",r)\n",
    "        i=i+1\n",
    "    \n",
    "    return (p,q,r)\n",
    "\n",
    "\n",
    "def printState(state):\n",
    "    #creating board skeleton\n",
    "    tableformat = '''\n",
    "               {} {} {} \n",
    "               {} {} {}\n",
    "               {} {} {}\n",
    "               -----\n",
    "             '''\n",
    "    p,q,r = getState(state)\n",
    "    # Creating Finished/final state P for all conditions \n",
    "    if (len(p)==0):\n",
    "        p=[' ',' ',' ']\n",
    "    elif (len(p)==1):\n",
    "        p=[' ',' ',p[0]]\n",
    "    elif (len(p)==2):\n",
    "        p=[' ',p[0],p[1]]\n",
    "    elif (len(p)==3):\n",
    "        p=[p[0],p[1],p[2]]\n",
    "        \n",
    "    # Creating Finished/final state q for all conditions \n",
    "    if (len(q)==0):\n",
    "        q=[' ',' ',' ']\n",
    "    elif (len(q)==1):\n",
    "        q=[' ',' ',q[0]]\n",
    "    elif (len(q)==2):\n",
    "        q=[' ',q[0],q[1]]\n",
    "    elif (len(q)==3):\n",
    "        q=[q[0],q[1],q[2]]\n",
    "        \n",
    "    # Creating Finished/final state r for all conditions \n",
    "    if (len(r)==0):\n",
    "        r=[' ',' ',' ']\n",
    "    elif (len(r)==1):\n",
    "        r=[' ',' ',r[0]]\n",
    "    elif (len(r)==2):\n",
    "        r=[' ',r[0],r[1]]\n",
    "    elif (len(r)==3):\n",
    "        r=[r[0],r[1],r[2]]\n",
    "        \n",
    "    #Inserting required values on given positions of board and printing it\n",
    "    tableformat_final = tableformat.format(p[0],q[0],r[0],p[1],q[1],r[1],p[2],q[2],r[2])\n",
    "    print (tableformat_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               1     \n",
      "               2    \n",
      "               3    \n",
      "               -----\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "state= [[1, 2, 3], [], []]\n",
    "printState(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next is function that return valid moves. This is based on game rule where, we cannot put big disk above small disk and one move at at time\n",
    "#Logic : 1st check length of p,q,r and based on that move by checking other tower  is empty or not ( if not check moving peg is smaller or not)\n",
    "# Update all possible moves to a new list\n",
    "def validMoves(state):\n",
    "    solution=[]\n",
    "    p,q,r=getState(state)\n",
    "    '''                     FOR LENGTH of 3 '''\n",
    "    if(len(p)==3):\n",
    "        return ([1,2],[1,3])\n",
    "    if(len(q)==3):\n",
    "        return ([2,1],[2,3])\n",
    "    if(len(r)==3):\n",
    "        return ([3,1],[3,2])\n",
    "    '''                     FOR LENGTH of 2 '''\n",
    "    #for P if len of 2\n",
    "    if(len(p)==2):\n",
    "        if( len(q))==0:\n",
    "            solution.append( [1,2])\n",
    "        else:           \n",
    "            if(p[0]<q[0]):\n",
    "                solution.append( [1,2])\n",
    "        if( len(r))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [1,3])\n",
    "        else:\n",
    "            if(p[0]<r[0]):\n",
    "                solution.append( [1,3])\n",
    "    #for q if len of 2\n",
    "    if(len(q)==2):\n",
    "        if( len(p))==0:\n",
    "            \n",
    "            solution.append( [2,1])\n",
    "        else:           \n",
    "            if(q[0]<p[0]):\n",
    "                solution.append( [2,1])\n",
    "        if( len(r))==0:\n",
    "            #print(\"pratik\")\n",
    "            solution.append( [2,3])\n",
    "        else:\n",
    "            if(q[0]<r[0]):\n",
    "                solution.append( [2,3])\n",
    "     #for r if len of 2\n",
    "    if(len(r)==2):\n",
    "        if( len(p))==0:\n",
    "            solution.append( [3,1])\n",
    "        else:           \n",
    "            if(r[0]<p[0]):\n",
    "                solution.append( [3,1])\n",
    "        if( len(q))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [3,2])\n",
    "        else:\n",
    "            if(r[0]<q[0]):\n",
    "                solution.append( [3,2])\n",
    "                \n",
    "    '''                     FOR LENGTH of 1 '''\n",
    "    \n",
    "    if(len(p)==1): \n",
    "        if(len(q)>0 ):\n",
    "            if(p[0]<q[0]):\n",
    "                solution.append( [1,2])\n",
    "        if ( len(r)>0):\n",
    "            if(p[0]<r[0]):\n",
    "                solution.append( [1,3])\n",
    "        \n",
    "        if (len(q)==0):\n",
    "                solution.append( [1,2])\n",
    "        if(len(r)==0):\n",
    "                solution.append( [1,3])\n",
    "    \n",
    "    #for q if len of 1\n",
    "    if(len(q)==1): \n",
    "        if(len(p)>0 ):\n",
    "            if(q[0]<p[0]):\n",
    "                solution.append( [2,1])\n",
    "        if ( len(r)>0):\n",
    "            if(q[0]<r[0]):\n",
    "                solution.append( [2,3])\n",
    "        \n",
    "        if (len(p)==0):\n",
    "                solution.append( [2,1])\n",
    "        if(len(r)==0):\n",
    "                solution.append( [2,3])\n",
    "    #for r if len of 1\n",
    "    if(len(r)==1): \n",
    "        if(len(p)>0): \n",
    "            if(r[0]<p[0]):\n",
    "                solution.append( [3,1])\n",
    "        if (len(q)>0):\n",
    "            if(r[0]<q[0]):\n",
    "                solution.append( [3,2])\n",
    "        \n",
    "        if (len(p)==0):\n",
    "                solution.append( [3,1])\n",
    "        if(len(q)==0):\n",
    "                solution.append( [3,2])\n",
    "                \n",
    "    return (solution)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2], [1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validMoves(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once we get valid move, Its time to make move.\n",
    "# makeMove function first getStates and then get 0th and 1st value from valid move. tmp list is use to append what peg we are moving and once it is moved, it is inserted in corresponging tower\n",
    "\n",
    "def makeMove(states, move): \n",
    "    newstate=[]\n",
    "    tmp=[]\n",
    "    p,q,r=getState(states)\n",
    "    #print(p)\n",
    "    if(move[0]==1):  \n",
    "        try:\n",
    "    #    print(p[0])\n",
    "            tmp.append(p[0]) \n",
    "            p.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[0]==2):\n",
    "        try:\n",
    "            tmp.append(q[0])\n",
    "            q.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[0]==3):\n",
    "        try:\n",
    "            tmp.append(r[0])\n",
    "            r.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "            \n",
    "    if(move[1]==1):  \n",
    "        try:\n",
    "            p.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[1]==2):\n",
    "        try:\n",
    "            q.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[1]==3):\n",
    "        try:\n",
    "            r.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "      \n",
    "                \n",
    "    \n",
    "   # print(p)    \n",
    "    return [p,q,r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [1], []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move =[1, 2]\n",
    "newstate = makeMove(state, move)\n",
    "newstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is handy function to covert list of list in tuple. This will be great help while updating Q values\n",
    "def stateMoveTuple(state, move):\n",
    "    p,q,r=getState(state)\n",
    "    #print(p,q,r)\n",
    "    return((tuple(p),tuple(q),tuple(r)),tuple(move))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((1, 2, 3), (), ()), (1, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateMoveTuple(state, move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainQ\n",
    "\n",
    "\n",
    "This function takes arguments nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF. In this fuction,we learn Q i.e a form of reinforcement learning in which the agent learns to assign values to state-move pairs. \n",
    "  \n",
    "The Q-value for a state-action pair is the sum of all of these reinforcements, and the Q-value is calculated by mapping from state-move pairs to values. \n",
    "\n",
    "If the agent knew the Q-values of every state-move pair, it could use this information to select an action for each state. \n",
    "\n",
    "Initially the agent  has no idea what the Q-values of any state-move pairs are. The agent's goal  is to settle on an optimal Q-value function, one which that assigns the appropriate values for all state/action pairs. But Q-values depend on future reinforcements, as well as current ones.\n",
    "\n",
    "\n",
    "If an moves in a given state causes something bad to happen, learn not to do that action in that situation. If an move in a given state causes something good to happen, learn to do that move in that situation.\n",
    "If all moves in a given state cause something bad to happen, learn to avoid that state. That is, don't take actions in other moves that would lead you to be in that bad state. If any move in a given moves causes something good to happen, learn to like that move.\n",
    "\n",
    "Because of Q- Learning, it able for agent to learn high or low values for particular actions from a particular state, even when there is no immediate reinforcement associated with those actions.\n",
    "\n",
    "\n",
    "To slowly transition from taking random actions to taking the action currently believed to be best, called the greedy action, we slowly decay a parameter, ϵϵ, from 1 down towards 0 as the probability of selecting a random action. This is called the ϵϵ-greedy policy.\n",
    "\n",
    "\n",
    "  \n",
    "                                  `Q(st,at)=Q(st,at)+ρ(rt+1+Q(st+1,at+1)−Q(st,at))`\n",
    "let's calculate the temporal difference error and the equation above is use to adjust the Q value of the previous board,move. The learning rate, rho, which controls the learning step size, that is, how fast learning takes place. The new Q-value for the state and action is the weighted combination of the old Q-value for that state and action and what the new information would lead us to goal or next state. On any given time step, the agent has a choice: it can pick the action with the highest Q-value for the state it is in (exploitation), or it can pick an action randomly when( `np.random.uniform() < epsilon`) (exploration).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TestQ : \n",
    "\n",
    "testQ funciton take argument ( Q, maxSteps, validMovesF, makeMoveF ). This is very easy as we don't update any Q values in this function. We use Q value from trainQ function to find greedy move or action for each step till goal is found. This function returns list of path. i.e we choose the best optimal action that was train and is reflected in Q values. Using argmax, we find the opitmal move and then move to next step and do it until maxsteps are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foundGoal(board):\n",
    "    # return goal state.\n",
    "    return board == [[],[],[1,2,3]]\n",
    "\n",
    "def trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF): \n",
    "    # Requried Import to pass grader file\n",
    "    import numpy as np\n",
    "    from random import choice\n",
    "    from copy import deepcopy\n",
    "    from copy import copy\n",
    "    \n",
    "    results = []                           #List to return i.e StepstoGoal.\n",
    "    maxGames = nRepetitions                           # number of games\n",
    "    rho = learningRate                              # learning rate\n",
    "    epsilonExp = epsilonDecayFactor                      # rate of epsilon decay\n",
    "    Q = {}                                  # initialize Q dictionary\n",
    "    epsilon = 1.0                           # initial epsilon value\n",
    "    printMoves = True                        # flag to print each board change                        \n",
    "    for game in range(maxGames):\n",
    "    \n",
    "        epsilon *= epsilonExp\n",
    "        step = 0\n",
    "        board = [[1, 2, 3], [], []]        # Initial Step\n",
    "        done = False\n",
    "        #to debug what moves are take uncomment bellow if block\n",
    "        #  if printMoves:\n",
    "        #     printState(board)\n",
    "        while not done:\n",
    "            step += 1\n",
    "            validMoves1 = validMoves(board)\n",
    "            if np.random.uniform() < epsilon:\n",
    "                # Randomly chooses list item\n",
    "                move = validMoves1[np.random.choice(len(validMoves1))]\n",
    "            else:\n",
    "                # Select move who has highest Q value                    \n",
    "                Qs = np.array([Q.get(stateMoveTuple(board,m), -1) for m in validMoves1]) \n",
    "                move= validMoves1[ np.argmax(Qs) ]  \n",
    "            #make Tuple of board and move\n",
    "            key=stateMoveTuple(board,move)\n",
    "            if key not in Q:\n",
    "                 Q[key] = 0\n",
    "            # Make move\n",
    "            movePlayed=makeMove(board,move)\n",
    "            boardNew = deepcopy(movePlayed)\n",
    "            if foundGoal(boardNew):\n",
    "                Q[key] = 0\n",
    "                done = True\n",
    "            if step > 1:\n",
    "                Q[stateMoveTuple(boardOld,moveOld)] += rho * (-1+Q[stateMoveTuple(board,move)] - Q[stateMoveTuple(boardOld,moveOld)])\n",
    "            boardOld,moveOld = deepcopy(board),copy(move)\n",
    "            board = boardNew\n",
    "        results.append((step))    \n",
    "    return (Q,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ(50, 0.5, 0.7, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(((), (1,), (2, 3)), (2, 3)): 0,\n",
       " (((), (1,), (2, 3)), (3, 1)): -0.9375,\n",
       " (((), (1, 2), (3,)), (2, 1)): -1.9999999999999467,\n",
       " (((), (1, 2), (3,)), (2, 3)): -2.3828125,\n",
       " (((), (1, 2), (3,)), (3, 1)): -2.85888671875,\n",
       " (((), (1, 2, 3), ()), (2, 1)): -3.84375,\n",
       " (((), (1, 2, 3), ()), (2, 3)): -3.9189453125,\n",
       " (((), (1, 3), (2,)), (2, 1)): -3.8134765625,\n",
       " (((), (1, 3), (2,)), (2, 3)): -3.59521484375,\n",
       " (((), (1, 3), (2,)), (3, 1)): -3.48681640625,\n",
       " (((), (2,), (1, 3)), (2, 1)): -1.8125,\n",
       " (((), (2,), (1, 3)), (3, 1)): -1.89892578125,\n",
       " (((), (2,), (1, 3)), (3, 2)): -1.90625,\n",
       " (((), (2, 3), (1,)), (2, 1)): -3.590576171875,\n",
       " (((), (2, 3), (1,)), (3, 1)): -3.453125,\n",
       " (((), (2, 3), (1,)), (3, 2)): -3.8642578125,\n",
       " (((), (3,), (1, 2)), (2, 1)): -4.2489013671875,\n",
       " (((), (3,), (1, 2)), (3, 1)): -4.0555419921875,\n",
       " (((), (3,), (1, 2)), (3, 2)): -3.8560791015625,\n",
       " (((1,), (), (2, 3)), (1, 2)): -0.5,\n",
       " (((1,), (), (2, 3)), (1, 3)): 0,\n",
       " (((1,), (), (2, 3)), (3, 2)): -1.375,\n",
       " (((1,), (2,), (3,)), (1, 2)): -1.5,\n",
       " (((1,), (2,), (3,)), (1, 3)): -1.5,\n",
       " (((1,), (2,), (3,)), (2, 3)): -1.0000000000000036,\n",
       " (((1,), (2, 3), ()), (1, 2)): -3.875732421875,\n",
       " (((1,), (2, 3), ()), (1, 3)): -3.48828125,\n",
       " (((1,), (2, 3), ()), (2, 3)): -3.4951171875,\n",
       " (((1,), (3,), (2,)), (1, 2)): -3.8155517578125,\n",
       " (((1,), (3,), (2,)), (1, 3)): -3.858642578125,\n",
       " (((1,), (3,), (2,)), (3, 2)): -3.6162109375,\n",
       " (((1, 2), (), (3,)), (1, 2)): -1.97265625,\n",
       " (((1, 2), (), (3,)), (1, 3)): -2.203125,\n",
       " (((1, 2), (), (3,)), (3, 2)): -2.248046875,\n",
       " (((1, 2), (3,), ()), (1, 2)): -2.9052734375,\n",
       " (((1, 2), (3,), ()), (1, 3)): -3.09521484375,\n",
       " (((1, 2), (3,), ()), (2, 3)): -2.73193359375,\n",
       " (((1, 2, 3), (), ()), (1, 2)): -6.01126766204834,\n",
       " (((1, 2, 3), (), ()), (1, 3)): -5.999999972131558,\n",
       " (((1, 3), (), (2,)), (1, 2)): -4.81182861328125,\n",
       " (((1, 3), (), (2,)), (1, 3)): -4.54486083984375,\n",
       " (((1, 3), (), (2,)), (3, 2)): -4.5552825927734375,\n",
       " (((1, 3), (2,), ()), (1, 2)): -3.9112095832824707,\n",
       " (((1, 3), (2,), ()), (1, 3)): -3.851318359375,\n",
       " (((1, 3), (2,), ()), (2, 3)): -3.8970947265625,\n",
       " (((2,), (), (1, 3)), (1, 2)): -2.0,\n",
       " (((2,), (), (1, 3)), (3, 1)): -1.71875,\n",
       " (((2,), (), (1, 3)), (3, 2)): -1.8515625,\n",
       " (((2,), (1,), (3,)), (1, 3)): -1.01953125,\n",
       " (((2,), (1,), (3,)), (2, 1)): -1.677734375,\n",
       " (((2,), (1,), (3,)), (2, 3)): -1.65625,\n",
       " (((2,), (1, 3), ()), (1, 3)): -3.318115234375,\n",
       " (((2,), (1, 3), ()), (2, 1)): -3.0234375,\n",
       " (((2,), (1, 3), ()), (2, 3)): -3.551025390625,\n",
       " (((2,), (3,), (1,)), (1, 2)): -3.537109375,\n",
       " (((2,), (3,), (1,)), (3, 1)): -3.320068359375,\n",
       " (((2,), (3,), (1,)), (3, 2)): -3.42529296875,\n",
       " (((2, 3), (), (1,)), (1, 2)): -4.999999997665103,\n",
       " (((2, 3), (), (1,)), (3, 1)): -5.878168106079102,\n",
       " (((2, 3), (), (1,)), (3, 2)): -5.132743835449219,\n",
       " (((2, 3), (1,), ()), (1, 3)): -5.340444564819336,\n",
       " (((2, 3), (1,), ()), (2, 1)): -5.701349973678589,\n",
       " (((2, 3), (1,), ()), (2, 3)): -5.518717646598816,\n",
       " (((3,), (), (1, 2)), (1, 2)): -4.38616943359375,\n",
       " (((3,), (), (1, 2)), (3, 1)): -4.50634765625,\n",
       " (((3,), (), (1, 2)), (3, 2)): -5.043426513671875,\n",
       " (((3,), (1,), (2,)), (2, 1)): -5.04693603515625,\n",
       " (((3,), (1,), (2,)), (2, 3)): -4.88055419921875,\n",
       " (((3,), (1,), (2,)), (3, 1)): -5.287393569946289,\n",
       " (((3,), (1, 2), ()), (1, 3)): -2.9999999999949782,\n",
       " (((3,), (1, 2), ()), (2, 1)): -3.0341796875,\n",
       " (((3,), (1, 2), ()), (2, 3)): -3.82489013671875,\n",
       " (((3,), (2,), (1,)), (2, 1)): -4.3327178955078125,\n",
       " (((3,), (2,), (1,)), (3, 1)): -4.055419921875,\n",
       " (((3,), (2,), (1,)), (3, 2)): -3.9999999998618954}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30,\n",
       " 215,\n",
       " 29,\n",
       " 27,\n",
       " 30,\n",
       " 32,\n",
       " 11,\n",
       " 14,\n",
       " 25,\n",
       " 19,\n",
       " 9,\n",
       " 9,\n",
       " 33,\n",
       " 26,\n",
       " 11,\n",
       " 7,\n",
       " 33,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 15,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testQ(Q, maxSteps, validMovesF, makeMove): \n",
    "    # Import for grader file to work\n",
    "    import numpy as np\n",
    "    from random import choice\n",
    "    from copy import deepcopy\n",
    "    from copy import copy\n",
    "\n",
    "    printMoves = True                        # flag to print each board chang\n",
    "    steps=0\n",
    "   \n",
    "    board1= [[1, 2, 3], [], []]   #initialize board\n",
    "    board=deepcopy(board1)\n",
    "    path=[board]\n",
    "    while steps<maxSteps and not foundGoal(board):  #loop through each step\n",
    "        #print(steps, board)\n",
    "        steps=steps+1\n",
    "        validMoves1 = validMoves(board)   #get valid moves\n",
    "        #print(validMoves1)\n",
    "        q=[]\n",
    "        for m in validMoves1:                          #get optimal action \n",
    "            q.append(Q.get(stateMoveTuple(board,m)) )      \n",
    "        #print(q)\n",
    "        move= validMoves1[ np.argmax(q) ]  \n",
    "        board = makeMove(board,move)       #make move\n",
    "        path.append(board)          #Append the found path\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3], [], []],\n",
       " [[2, 3], [], [1]],\n",
       " [[3], [2], [1]],\n",
       " [[3], [1, 2], []],\n",
       " [[], [1, 2], [3]],\n",
       " [[1], [2], [3]],\n",
       " [[1], [], [2, 3]],\n",
       " [[], [], [1, 2, 3]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path1=testQ(Q, 20, validMoves, makeMove)\n",
    "path1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               1     \n",
      "               2    \n",
      "               3    \n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "               2    \n",
      "               3   1\n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "                    \n",
      "               3 2 1\n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "                 1  \n",
      "               3 2  \n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "                 1  \n",
      "                 2 3\n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "                    \n",
      "               1 2 3\n",
      "               -----\n",
      "             \n",
      "\n",
      "                     \n",
      "                   2\n",
      "               1   3\n",
      "               -----\n",
      "             \n",
      "\n",
      "                   1 \n",
      "                   2\n",
      "                   3\n",
      "               -----\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "for s in path1:\n",
    "    printState(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing validMoves([[1], [2], [3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[1, 2], [1, 3], [2, 3]]\n",
      "\n",
      "Testing validMoves([[], [], [1, 2, 3]])\n",
      "\n",
      "--- 10/10 points. Correctly returned ([3, 1], [3, 2])\n",
      "\n",
      "Testing makeMove([[], [], [1, 2, 3]], [3, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [1], [2, 3]]\n",
      "\n",
      "Testing makeMove([[2], [3], [1]], [1, 2])\n",
      "\n",
      "--- 10/10 points. Correctly returned [[], [2, 3], [1]]\n",
      "\n",
      "Testing   Q, steps = trainQ(1000, 0.5, 0.7, validMoves, makeMove).\n",
      "\n",
      "--- 10/10 points. Q dictionary has correct number of entries.\n",
      "\n",
      "--- 10/10 points. The mean of the number of steps is 7.542 which is correct.\n",
      "\n",
      "Testing   path = testQ(Q, 20, validMoves, makeMove).\n",
      "\n",
      "--- 20/20 points. Correctly returns path of length 8, less than 10.\n",
      "\n",
      "C:\\Users\\waradepratik Execution Grade is 80/80\n",
      "\n",
      " Remaining 20 points will be based on your text describing the trainQ and test! functions.\n",
      "\n",
      "C:\\Users\\waradepratik FINAL GRADE is __/100\n"
     ]
    }
   ],
   "source": [
    "%run -i A5grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extra Credit\n",
    "\n",
    "Task : Modify your code to solve the Towers of Hanoi puzzle with 4 disks instead of 3.\n",
    "I have implemented sperate trainQ and TestQ fuction as, I have to make modifications in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printState_4disk(state):\n",
    "   \n",
    "    #creating board skeleton\n",
    "    tableformat = '''\n",
    "               {} {} {}\n",
    "               {} {} {} \n",
    "               {} {} {}\n",
    "               {} {} {}\n",
    "               -----\n",
    "             '''\n",
    "    p,q,r = getState(state)\n",
    "    # Creating Finished/final state P for all conditions \n",
    "   # print(len(p))\n",
    "    if (len(p)==0):\n",
    "        p=[' ',' ',' ',' ']\n",
    "    elif (len(p)==1):\n",
    "        p=[' ',' ',' ',p[0]]\n",
    "    elif (len(p)==2):\n",
    "        p=[' ',' ',p[0],p[1]]\n",
    "    elif (len(p)==3):\n",
    "        p=[' ',p[0],p[1],p[2]]\n",
    "    elif (len(p)==4):\n",
    "        p=[p[0],p[1],p[2],p[3]]\n",
    "    # Creating Finished/final state q for all conditions \n",
    "    if (len(q)==0):\n",
    "        q=[' ',' ',' ',' ']\n",
    "    elif (len(q)==1):\n",
    "        q=[' ',' ',' ',q[0]]\n",
    "    elif (len(q)==2):\n",
    "        q=[' ',' ',q[0],q[1]]\n",
    "    elif (len(q)==3):\n",
    "        q=[' ',q[0],q[1],q[2]]\n",
    "    elif (len(q)==4):\n",
    "        q=[q[0],q[1],q[2],q[3]]\n",
    "    # Creating Finished/final state r for all conditions \n",
    "    if (len(r)==0):\n",
    "        r=[' ',' ',' ',' ']\n",
    "    elif (len(r)==1):\n",
    "        r=[' ',' ',' ',r[0]]\n",
    "    elif (len(r)==2):\n",
    "        r=[' ',' ',r[0],r[1]]\n",
    "    elif (len(r)==3):\n",
    "        r=[' ',r[0],r[1],r[2]]\n",
    "    elif (len(r)==4):\n",
    "        r=[r[0],r[1],r[2],r[3]]\n",
    "    #Inserting required values on given positions of board and printing it\n",
    "    tableformat_final = tableformat.format(p[0],q[0],r[0],p[1],q[1],r[1],p[2],q[2],r[2],p[3],q[3],r[3])\n",
    "    print (tableformat_final)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               1    \n",
      "               2     \n",
      "               3    \n",
      "               4    \n",
      "               -----\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "state=[[1,2,3,4],[],[]]\n",
    "printState_4disk(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validMoves_4disk(state):\n",
    "    solution=[]\n",
    "    p,q,r=getState(state)\n",
    "\n",
    "    '''                     FOR LENGTH of 4 '''\n",
    "    if(len(p)==4):\n",
    "        return ([1,2],[1,3])\n",
    "    if(len(q)==4):\n",
    "        return ([2,1],[2,3])\n",
    "    if(len(r)==4):\n",
    "        return ([3,1],[3,2])\n",
    "    \n",
    "    '''                     FOR LENGTH of 3 '''\n",
    "    if(len(p)==3):\n",
    "        if( len(q))==0:\n",
    "            solution.append( [1,2])\n",
    "        else:    \n",
    "            if(p[0]<q[0]):\n",
    "                solution.append( [1,2])\n",
    "        if( len(r))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [1,3])\n",
    "        else:\n",
    "            if(p[0]<r[0]):\n",
    "                solution.append( [1,3])\n",
    "       \n",
    "    if(len(q)==3):\n",
    "        if( len(p))==0:\n",
    "            \n",
    "            solution.append( [2,1])\n",
    "        else:\n",
    "            if(q[0]<p[0]):\n",
    "                solution.append( [2,1])\n",
    "        if( len(r))==0:\n",
    "            #print(\"pratik\")\n",
    "            solution.append( [2,3])\n",
    "        else:\n",
    "            if(q[0]<r[0]):\n",
    "                solution.append( [2,3])\n",
    "    \n",
    "    if(len(r)==3):\n",
    "        if( len(p))==0:\n",
    "            solution.append( [3,1])\n",
    "        else:       \n",
    "            if(r[0]<p[0]):\n",
    "                solution.append( [3,1])\n",
    "        if( len(q))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [3,2])\n",
    "        else:\n",
    "            if(r[0]<q[0]):\n",
    "                solution.append( [3,2])\n",
    "    '''                     FOR LENGTH of 2 '''\n",
    "    #for P if len of 2\n",
    "    if(len(p)==2):\n",
    "        if( len(q))==0:\n",
    "            solution.append( [1,2])\n",
    "        else:       \n",
    "            if(p[0]<q[0]):\n",
    "                solution.append( [1,2])\n",
    "        if( len(r))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [1,3])\n",
    "        else:\n",
    "            if(p[0]<r[0]):\n",
    "                solution.append( [1,3])\n",
    "    #for q if len of 2\n",
    "    if(len(q)==2):\n",
    "        if( len(p))==0:\n",
    "            \n",
    "            solution.append( [2,1])\n",
    "        else:      \n",
    "            if(q[0]<p[0]):\n",
    "                solution.append( [2,1])\n",
    "        if( len(r))==0:\n",
    "            #print(\"pratik\")\n",
    "            solution.append( [2,3])\n",
    "        else:\n",
    "            if(q[0]<r[0]):\n",
    "                solution.append( [2,3])\n",
    "     #for r if len of 2\n",
    "    if(len(r)==2):\n",
    "        if( len(p))==0:\n",
    "            solution.append( [3,1])\n",
    "        else:      \n",
    "            if(r[0]<p[0]):\n",
    "                solution.append( [3,1])\n",
    "        if( len(q))==0:\n",
    "           # print(\"pratik\")\n",
    "            solution.append( [3,2])\n",
    "        else:\n",
    "            if(r[0]<q[0]):\n",
    "                solution.append( [3,2])\n",
    "                \n",
    "    '''                     FOR LENGTH of 1 '''\n",
    "    \n",
    "    if(len(p)==1): \n",
    "        if(len(q)>0 ):\n",
    "            if(p[0]<q[0]):\n",
    "                solution.append( [1,2])\n",
    "        if ( len(r)>0):\n",
    "            if(p[0]<r[0]):\n",
    "                solution.append( [1,3])\n",
    "        \n",
    "        if (len(q)==0):\n",
    "                solution.append( [1,2])\n",
    "        if(len(r)==0):\n",
    "                solution.append( [1,3])\n",
    "    \n",
    "    \n",
    "    if(len(q)==1): \n",
    "        if(len(p)>0 ):\n",
    "            if(q[0]<p[0]):\n",
    "                solution.append( [2,1])\n",
    "        if ( len(r)>0):\n",
    "            if(q[0]<r[0]):\n",
    "                solution.append( [2,3])\n",
    "        \n",
    "        if (len(p)==0):\n",
    "                solution.append( [2,1])\n",
    "        if(len(r)==0):\n",
    "                solution.append( [2,3])\n",
    "    if(len(r)==1): \n",
    "        if(len(p)>0): \n",
    "            if(r[0]<p[0]):\n",
    "                solution.append( [3,1])\n",
    "        if (len(q)>0):\n",
    "            if(r[0]<q[0]):\n",
    "                solution.append( [3,2])\n",
    "        \n",
    "        if (len(p)==0):\n",
    "                solution.append( [3,1])\n",
    "        if(len(q)==0):\n",
    "                solution.append( [3,2])\n",
    "                \n",
    "    return (solution)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3], [2, 1], [2, 3]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[[2,3,4],[1],[]]\n",
    "validMoves_4disk(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMove_4disk(states, move):\n",
    "    newstate=[]\n",
    "    tmp=[]\n",
    "    p,q,r=getState(states)\n",
    "    #print(p)\n",
    "    if(move[0]==1):  \n",
    "        try:\n",
    "    #    print(p[0])\n",
    "            tmp.append(p[0]) \n",
    "            p.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[0]==2):\n",
    "        try:\n",
    "            tmp.append(q[0])\n",
    "            q.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[0]==3):\n",
    "        try:\n",
    "            tmp.append(r[0])\n",
    "            r.pop(0)\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "            \n",
    "    if(move[1]==1):  \n",
    "        try:\n",
    "            p.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[1]==2):\n",
    "        try:\n",
    "            q.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")\n",
    "    elif(move[1]==3):\n",
    "        try:\n",
    "            r.insert(0,tmp[0])\n",
    "        except:\n",
    "            print(\"INVALID\")        \n",
    "    \n",
    "   # print(p)    \n",
    "    return [p,q,r]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4], [], [1]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move=[1,3]\n",
    "state=[[1,2,3,4],[],[]]\n",
    "makeMove_4disk(state,move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foundGoal_4(board):\n",
    "    # return goal state.\n",
    "    return board == [[],[],[1,2,3,4]]\n",
    "\n",
    "def trainQ4(nRepetitions, learningRate, epsilonDecayFactor, validMovesF, makeMoveF): \n",
    "    # Requried Import to pass grader file\n",
    "    import numpy as np\n",
    "    from random import choice\n",
    "    from copy import deepcopy\n",
    "    from copy import copy\n",
    "    \n",
    "    results = []                           #List to return i.e StepstoGoal.\n",
    "    maxGames = nRepetitions                           # number of games\n",
    "    rho = learningRate                              # learning rate\n",
    "    epsilonExp = epsilonDecayFactor                      # rate of epsilon decay\n",
    "    Q = {}                                  # initialize Q dictionary\n",
    "    epsilon = 1.0                           # initial epsilon value\n",
    "    printMoves = True                        # flag to print each board change                        \n",
    "    for game in range(maxGames):\n",
    "    \n",
    "        epsilon *= epsilonExp\n",
    "        step = 0\n",
    "        board = [[1, 2, 3,4], [], []]        # Initial Step\n",
    "        done = False\n",
    "        #to debug what moves are take uncomment bellow if block\n",
    "        #  if printMoves:\n",
    "        #     printState(board)\n",
    "        while not done:\n",
    "            step += 1\n",
    "            validMoves1 = validMoves_4disk(board)\n",
    "            if np.random.uniform() < epsilon:\n",
    "                # Randomly chooses list item\n",
    "                move = validMoves1[np.random.choice(len(validMoves1))]\n",
    "            else:\n",
    "                # Select move who has highest Q value                    \n",
    "                Qs = np.array([Q.get(stateMoveTuple(board,m), -1) for m in validMoves1]) \n",
    "                move= validMoves1[ np.argmax(Qs) ]  \n",
    "            #make Tuple of board and move\n",
    "            key=stateMoveTuple(board,move)\n",
    "            if key not in Q:\n",
    "                 Q[key] = 0\n",
    "            # Make move\n",
    "            movePlayed=makeMove(board,move)\n",
    "            boardNew = deepcopy(movePlayed)\n",
    "            if foundGoal_4(boardNew):\n",
    "                Q[key] = 0\n",
    "                done = True\n",
    "            if step > 1:\n",
    "                Q[stateMoveTuple(boardOld,moveOld)] += rho * (-1+Q[stateMoveTuple(board,move)] - Q[stateMoveTuple(boardOld,moveOld)])\n",
    "            boardOld,moveOld = deepcopy(board),copy(move)\n",
    "            board = boardNew\n",
    "        results.append((step))    \n",
    "    return (Q,results)\n",
    "\n",
    "def testQ4(Q, maxSteps, validMovesF, makeMove): \n",
    "    # Imports for grader file to work\n",
    "    import numpy as np\n",
    "    from random import choice\n",
    "    from copy import deepcopy\n",
    "    from copy import copy\n",
    "\n",
    "    printMoves = True                        # flag to print each board chang\n",
    "    steps=0\n",
    "   \n",
    "    board1= [[1, 2, 3,4], [], []]   #initialize board\n",
    "    board=deepcopy(board1)\n",
    "    path=[board]\n",
    "    while steps<maxSteps and not foundGoal_4(board): \n",
    "        #print(steps, board)\n",
    "        steps=steps+1\n",
    "        validMoves1 = validMoves_4disk(board)\n",
    "        #print(validMoves1)\n",
    "        q=[]\n",
    "        for m in validMoves1:\n",
    "            q.append(Q.get(stateMoveTuple(board,m)) )\n",
    "        #print(q)\n",
    "        move= validMoves1[ np.argmax(q) ]\n",
    "        board = makeMove_4disk(board,move)\n",
    "        path.append(board)\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running for bunch of combinations for number of repetitions, learning rate, and epsilon decay factor, I found bellow combination which gave me shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q, stepsToGoal = trainQ4(150, 0.5, 0.7, validMoves_4disk, makeMove_4disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[872,\n",
       " 121,\n",
       " 38,\n",
       " 293,\n",
       " 327,\n",
       " 86,\n",
       " 53,\n",
       " 58,\n",
       " 67,\n",
       " 52,\n",
       " 171,\n",
       " 163,\n",
       " 35,\n",
       " 155,\n",
       " 66,\n",
       " 52,\n",
       " 18,\n",
       " 146,\n",
       " 71,\n",
       " 127,\n",
       " 59,\n",
       " 33,\n",
       " 57,\n",
       " 29,\n",
       " 60,\n",
       " 109,\n",
       " 23,\n",
       " 70,\n",
       " 45,\n",
       " 71,\n",
       " 91,\n",
       " 28,\n",
       " 47,\n",
       " 37,\n",
       " 17,\n",
       " 103,\n",
       " 44,\n",
       " 24,\n",
       " 28,\n",
       " 63,\n",
       " 37,\n",
       " 35,\n",
       " 16,\n",
       " 41,\n",
       " 20,\n",
       " 123,\n",
       " 21,\n",
       " 22,\n",
       " 42,\n",
       " 19,\n",
       " 39,\n",
       " 20,\n",
       " 43,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 19,\n",
       " 44,\n",
       " 16,\n",
       " 18,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 46,\n",
       " 30,\n",
       " 16,\n",
       " 30,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 15]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepsToGoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4], [], []],\n",
       " [[2, 3, 4], [1], []],\n",
       " [[3, 4], [1], [2]],\n",
       " [[3, 4], [], [1, 2]],\n",
       " [[4], [3], [1, 2]],\n",
       " [[1, 4], [3], [2]],\n",
       " [[1, 4], [2, 3], []],\n",
       " [[4], [1, 2, 3], []],\n",
       " [[], [1, 2, 3], [4]],\n",
       " [[], [2, 3], [1, 4]],\n",
       " [[2], [3], [1, 4]],\n",
       " [[1, 2], [3], [4]],\n",
       " [[1, 2], [], [3, 4]],\n",
       " [[2], [1], [3, 4]],\n",
       " [[], [1], [2, 3, 4]],\n",
       " [[], [], [1, 2, 3, 4]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=testQ4(Q, 20, validMoves_4disk, makeMove_4disk)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               1    \n",
      "               2     \n",
      "               3    \n",
      "               4    \n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "               2     \n",
      "               3    \n",
      "               4 1  \n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               3    \n",
      "               4 1 2\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               3   1\n",
      "               4   2\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "                   1\n",
      "               4 3 2\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               1    \n",
      "               4 3 2\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               1 2  \n",
      "               4 3  \n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                 1   \n",
      "                 2  \n",
      "               4 3  \n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                 1   \n",
      "                 2  \n",
      "                 3 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "                 2 1\n",
      "                 3 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "                   1\n",
      "               2 3 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               1    \n",
      "               2 3 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "               1   3\n",
      "               2   4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                     \n",
      "                   3\n",
      "               2 1 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                    \n",
      "                   2 \n",
      "                   3\n",
      "                 1 4\n",
      "               -----\n",
      "             \n",
      "\n",
      "                   1\n",
      "                   2 \n",
      "                   3\n",
      "                   4\n",
      "               -----\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "for s in path:\n",
    "    printState_4disk(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find values for number of repetitions, learning rate, and epsilon decay factor for which trainQ learns a Q function that testQ can use to find the shortest solution path. Include the output from the successful calls to trainQ and testQ.?\n",
    "  \n",
    "Ans:  Shortest path length is 15 ( excluding start state). Number of repitions = 150 , learning rate =0.5 , and epsilon decay factor =0.7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
